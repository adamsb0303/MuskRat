{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When input image is selected, run it through models and make predictions \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_builder = keras.applications.xception.Xception\n",
    "img_size = (128, 128)\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"conv2d\"\n",
    "\n",
    "# The local path to our target image\n",
    "img_path = 'C:\\\\Users\\\\624411\\\\Desktop\\\\Project_working\\\\MuskRat\\\\thisone\\\\test_internet\\\\fake_image\\\\elon_musk_fake.jpg'\n",
    "\n",
    "display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "CATEGORIES = ['real', 'fake']\n",
    "\n",
    "model1 = keras.models.load_model('double_trained_model.h5')\n",
    "model2 = keras.models.load_model('model_00_20.h5')\n",
    "model3 = keras.models.load_model('model_20_40.h5')\n",
    "model4 = keras.models.load_model('model_40_60.h5')\n",
    "model5 = keras.models.load_model('model_q2_q4.h5')\n",
    "\n",
    "MODELS = [model1, model2, model3, model4, model5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function ingests a Lists, returns the most frequent value in list\n",
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    " \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_array(img):\n",
    "    pred = []\n",
    "\n",
    "    for mod in MODELS:\n",
    "        predictions = mod.predict(img)\n",
    "        pred.append(int(predictions[0][0]))\n",
    "    #append the most frequent result on total_pred list so that we return 1 list\n",
    "    pred.append(most_frequent(pred))\n",
    "    #print(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, classIdx, layerName=None):\n",
    "        self.model = model\n",
    "        self.classIdx = classIdx\n",
    "        self.layerName = layerName\n",
    "        if self.layerName is None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "\n",
    "    #setter has list in parameters\n",
    "    def set_model(self, mod):\n",
    "        self.model = mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_layer(model):\n",
    "\t# attempt to find the final convolutional layer in the network\n",
    "\t# by looping over the layers of the network in reverse order\n",
    "\tfor layer in reversed(model.layers):\n",
    "\t\t# check to see if the layer has a 4D output\n",
    "\t\tif len(layer.output_shape) == 4:\n",
    "\t\t\treturn layer.name\n",
    "\t# otherwise, we could not find a 4D layer so the GradCAM\n",
    "\t# algorithm cannot be applied\n",
    "\traise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heatmap(self, image, eps=1e-8):\n",
    "    # construct our gradient model by supplying (1) the inputs\n",
    "    # to our pre-trained model, (2) the output of the (presumably)\n",
    "    # final 4D layer in the network, and (3) the output of the\n",
    "    # softmax activations from the model\n",
    "    gradModel = Model(\n",
    "        inputs=[self.model.inputs],\n",
    "        outputs=[self.model.get_layer(self.layerName).output,\n",
    "            self.model.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_predictions(img_path):\n",
    "    #parameter is path to input file on local machine \n",
    "    #convert image to grayscale \n",
    "    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #plt.imshow(img_array, cmap=\"gray\")\n",
    "    #plt.show()\n",
    "\n",
    "    #resize image to fit model input layer\n",
    "    img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    img_array = img_array.reshape(-1, 128, 128, 1)\n",
    "    #compute_heatmap(img_array)\n",
    "\n",
    "    #i = 0\n",
    "    temp_list = []\n",
    "    #make a prediction with each model\n",
    "    for mod in MODELS:\n",
    "        target_layer_name = find_target_layer(mod)\n",
    "        print(target_layer_name)\n",
    "        predictions = mod.predict(img_array)\n",
    "        temp_list.append(int(predictions[0][0]))\n",
    "\n",
    "        #heatmap\n",
    "        # Remove last layer's softmax\n",
    "        mod.layers[-1].activation = None\n",
    "\n",
    "        \n",
    "        # Print what the top predicted class is\n",
    "        preds = mod.predict(img_array)\n",
    "        #print(\"Predicted Class Model \" + str(i) + \": \" + CATEGORIES[int(predictions[0][0])])\n",
    "        #i = i + 1\n",
    "    pred = prediction_array(img_array)\n",
    "    print(\"hey\")\n",
    "    print(\"Predicted:\", decode_predictions(pred, top=1)[0])\n",
    "    #print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_array, mod, last_conv_layer_name)\n",
    "\n",
    "    # Display heatmap\n",
    "    plt.matshow(heatmap)\n",
    "    plt.show()\n",
    "    #print(\"here\")\n",
    "    #print(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hey\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\624411\\Desktop\\gui\\test_hm.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=0'>1</a>\u001b[0m get_list_of_predictions(img_path)\n",
      "\u001b[1;32mc:\\Users\\624411\\Desktop\\gui\\test_hm.ipynb Cell 12\u001b[0m in \u001b[0;36mget_list_of_predictions\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=29'>30</a>\u001b[0m pred \u001b[39m=\u001b[39m prediction_array(img_array)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhey\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPredicted:\u001b[39m\u001b[39m\"\u001b[39m, decode_predictions(pred, top\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=32'>33</a>\u001b[0m \u001b[39m#print(\"Predicted:\", decode_predictions(preds, top=1)[0])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=33'>34</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=34'>35</a>\u001b[0m \u001b[39m# Generate class activation heatmap\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=35'>36</a>\u001b[0m heatmap \u001b[39m=\u001b[39m make_gradcam_heatmap(img_array, mod, last_conv_layer_name)\n",
      "File \u001b[1;32mc:\\Users\\624411\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\applications\\xception.py:324\u001b[0m, in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.applications.xception.decode_predictions\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_predictions\u001b[39m(preds, top\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n\u001b[1;32m--> 324\u001b[0m   \u001b[39mreturn\u001b[39;00m imagenet_utils\u001b[39m.\u001b[39;49mdecode_predictions(preds, top\u001b[39m=\u001b[39;49mtop)\n",
      "File \u001b[1;32mc:\\Users\\624411\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:146\u001b[0m, in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m\"\"\"Decodes the prediction of an ImageNet model.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m    (must be 2D).\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39mglobal\u001b[39;00m CLASS_INDEX\n\u001b[1;32m--> 146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(preds\u001b[39m.\u001b[39;49mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m preds\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m    147\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`decode_predictions` expects \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    148\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39ma batch of predictions \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    149\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m(i.e. a 2D array of shape (samples, 1000)). \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    150\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mFound array with shape: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(preds\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m CLASS_INDEX \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "get_list_of_predictions(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c466081faad3890721e1057afad1ed119f8f73d11717f0d7d135755f98d78ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
