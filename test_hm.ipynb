{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When input image is selected, run it through models and make predictions \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_builder = keras.applications.xception.Xception\n",
    "img_size = (299, 299)\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"block14_sepconv2_act\"\n",
    "\n",
    "# The local path to our target image\n",
    "img_path = 'C:\\\\Users\\\\624411\\\\Desktop\\\\Project_working\\\\MuskRat\\\\thisone\\\\test_internet\\\\fake_image\\\\elon_musk_fake.jpg'\n",
    "\n",
    "display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block14_sepconv2_act\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted: [('n04350905', 'suit', 8.422052)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 345.6x345.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare image\n",
    "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "\n",
    "# Make model\n",
    "model = model_builder(weights=\"imagenet\")\n",
    "target_layer = find_target_layer(model)\n",
    "print(target_layer)\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = model.predict(img_array)\n",
    "print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAC0AUADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDzfFIRTzRivsje4zFJipMUlMYzFJipNtNxQFxmKXFOxRimA3FDUtFAxlFOxRigQ2inYophcbRinUYoAbQRQSq0nmD1qHJIV0OoFN85PWk+0J60vaR7hzIkp2KrtcqvYmpI50f+MUlUj3FzIkpcU3zl3YFSg1al2C6EApadQTR1FcTFLSilxQFxppwFLijFMQmKXbSgUtIBMUYpcUUBcTFFLilxQwuNoxS7aNtILiUYpcUYoAhxRTsUYphcYRSYp9GKB3GYoNOxSYoC43FJin4pCKB3G0mKdikxTC40iilxS4oC43FFOxSNwtN9x3GO+1c+lU2vlZiBxTZpfOyEPyjqarsEXjivOrYh3sjKUuiJHcvyZCOegoG3rv6VAGXpUiru6Vy+0b3Is2PBzzzQNqdKckTr2J/CpFti3/LNvyqecagxpdfrTSy7s4x9Kn+z3CdISfwqNluIuZIMD3WjnYcjJIHWXI7irKyeVGM8msd5NsmR8vPAqdLjdyT0raOIaQ+pZldnb75z3wasWkm5ijt06Vn+dvk2R9O7VLHH83JwfWnRrS5rsLs2MUVDayM8ZR/vJwcVPivUi7q47hijFKBS4pgJilxTsUYpWC4mKKXFGKAExRS4oIpajEFFKRSUXAQ0tFLQBFikxS0GmFxuKTFPoNIYzFJinYopiuNIpKcRSYoGNIpKdRTsAwCgU8igCmguJVLUZvKtyO7DFXsVja0/7xU9OtZV3y02xN6GeJG20kYeaYIgJJ9KYoPbmuk8P6ftXz5E+ZjxnsK8bXchK7JtP8N71Dyvyewrobbw1CI+mR3NWIExitBJMR4qlY2USpHpFtD0QH8KlFnbr/yzX8qm8zdRms5eRrFIi8iJf+Wa+3FRy2sMq4eNSPQirJFNZazuy7I5PXNBTy/Pt1xjqBXOfZCv3zge1ei3SboSDXGahE0Uh4+laROepGzM8YiXCCguzVGS360uataGRpaa+6Q+uMGtPFZOlnbcEeo4rXxXrYZ3gAgFLilFBFdFguIKWilAqRCUUoFLikMbiinYoxSuISgilxRQO43FGKXFLQFyCkqQ000ANoxS4opgIKSnUUXAbikNOzSUwuNopSKSmhiUUtGKtIVwrntWbddt7V0Vc9rCbLg/7XNc+Mj+7C+hWs1aW6WMdCa7i0VYlAHauV8PxK1wzkfdrrYhXktFUy/E9XEqrbp8oq4AvrSsdCAVIAaYv3qnMsUS5kdVHuaVixlO27qh/tC0ZsCVSfY1KJFK5ByKhxBO5DPDmM/SuU1UNuOe1dizVmX2nxXUZ7N6inHQicbnByDrVbftbBrQurd4bhoyPums6ZfmrQ5mtTU0gbpifRa2cVj6Gv8ArDW1XrYRfuyHuJRilxS4rdgJiginCg1IxuKWlNFSAZoooqQCkpcUtADaKWjFAEVNp1FMBmKDT6TFADMUYp2KSgBuKSnUUwG0lPpMVSC42igiitEIKq31it6oycMOhq2BTgKpwUlZjM7R7b7PJMh6g4roI5oYcea4B9Kx8+VNMQcE4Ip0cNtKplu5Cq55O6vErx5JtGkNDo4ru3ZfkkB+lS+b6GudhOjc/ZribzPUqSKuafMzXIiL7gehFYM2izUeZkWsia0u76be822MHua2byDZCHHPsKx2je4uRHO5SIDoKSKlsTQaQq8+aGI6gGrkaPb/ACo5x6GsXTdLuPtpM6FYlDfvFcgk9q2YYrhV/ev5gHR8c/jTb0JjqXkkyv8AOhjSxxfLmmyDbWTZZzOqov2tjjrWBd7N1dDrB2TZ9adZaLZ/ZluLiNp5nGVQH9KtStuYuF2V7CJEt1cdxkYq3TIpBKpxAYdpxsPapMV7mGmpU1YxnFxdgxRSikrRsgKUUlLUsYGig0gqWAuKBRRUgAoNBpKBhRmiigCKjNLTaZKA0maM0Uh3FFIRSilpgNIpKeKaRTAbRSmkq0A0ijFKelLmtEAgWlxQKUmrQrkEi/vh/tLio44m+0qX5VDwMcVYdcsp/umryIrL06ivKx0bVLm1Mr6VYpaTNLvLg/wN05q1AiLqMQQYx1qaOP5aitf+Qif9k1wxWpqlY2pBu+T+dUZbR1k3kZ9xVqbcuDR5275TwaUtGbW0GQKvGQfxq+uNuO3pVaM/NU9Q7gkPI+XiqVw9PeVulQON1TYLGXfQfaJox6Vc0u8t/tDW5TDR8BvWprZB9rXPoetQvaol75kf97oKGtBRSuOvLZIo2kA5LVnVpahKp/dj15rONe1gINUjmxDXNoNIopTQK6mjnDFApaKljuGKMUUlZhcMU6kopDDFJinUUDGUUuKSgCOinUhFBI3FJTsUmKYhtLmlxRigdxKDS4pCKpBcSkpQKQ1SC4hoApaditEhXG4p22nBaeErZEuRCV+U1PbPuUCniOo4l2SV52YrRSLp1LGgoIXNZc87W9yDtOD1I7VtRpuh6VHJp63HbmvF9rY1lWSKbX11cRr9jWN2B+beeK0IfPuY182JUlHUKeKuWWjxWv8Aq05PUmtRLXH8NRKshxrmPErRSYPTtVpwdtXmtQ/bml+ye1Z+2Rf1gyBGWoaM1q/Y8dqRrX2o9uhe3RhhCsw+tW3tDt4/djuV61NLb7GzjpWNqWvm4tntbeFllPyl88CtIVOdpIX1iMdSGVP3h28gHioyhrQitm8lcjsKGgx2r6ai1GCSOCWIUpGcUNBWrjQ4qMx1puUqlysFpcVMUphWpcS1IjxSYpxFGKycSrjaM0uKMVNh3Cg0UlSO4GkAoooAbTcU6kNMi7EFGKDQaEMTFGKWijcLje9BpaO9WgG4pKcaTFaxQriAVIFpFqZVzV2sRKVgValRKkSPNWEhpOdjnlUIUjpDD+8q8sNMmj2MDXm5hPmpPyJhO7JIAUhORTP7RWFiETc3vV62jS4jKN6VA9qsMhKIPc4r5SeJRv7OTYRatdvxHBz67auR3mp9SkZ9mNLDI3QJWhDHnBZMVi8UjaNFkEb37rveBAP9lq0LbLx88H3qUYVdtRkFeRWcsSmX9XmPZBUTgU7cdtV5ZNtR7cf1eSIbnH51yENsV1OcccP3rqdxnk9qz3WKK6uZ9hIRv3hH8IPQ/SuvC4hKWrOerQkywsY8sZ/So3i9qsRSxSx5jcMPalZc19NSxKtucfspIzniqBoq02izUZgruhiUWk0ZjR1EyVptB7VA8PtW6rJmkZGcy0zFXHjqFkqr3NlIgoqQrTSKhxKuMopSKSs2ihppKU0lSMbRRTc0XJA0UUUAJS0lLQgFpO9FLWsNxCEUlOIoxXTFCbFQc1ZjWoY15q5EtRUdjKbJokq5HHTIUq2q8V59WukcsotjRHSvBvhYeo61KFpeledWrKSaNqVJ3M63d4ZNvcGtSNlm579xWTqE6QzKf4mPIqOLUDHJwfwr4/FxlGbSPZoUro6NFVe1XI5F4Fc4mphuc1KNSHXdXIozO6FKK6HRmRO9VZrxF6MKwJNY/wBqqj3ZfndVqEuptyxOja/QL7+1UXuTK2B61lLM7N1rStIujk81XK0P2akXbdNi+9U9Ni87xi1o/MVzEyyDtjFaC7QvWp/DNmr6nf6o44SMRRk+vcj9KI81xTw65bnDebNpeozRZP7pypB7gV0dpdxXkIdDz3X0rnPE0i/8JDckdC1U7a7eCTMblT7V6VDFTpPXY8urh0dyEzQYxWPp+t+YwSfAz/FW71+7zXq0sWpbHn1KViu8VVpIq0SvFV5Er0aNe5g4NGXLHVV0rTkSqkiV61GdxXsUStMZatMlRMtdDNIyK5FNNSsKjasZI1TG00ilNJUWKIzSUtIaRKYUUUlAXCiiigBaUUw0oNawEPpQKQUoNdcdiGTxirsQqlGeauxGuTEXsSXolq2o4qrEatoa8HEOVy0kLjisy/1JLZSifNJ/Kp9QvUt4WQP+8I4ArlpmLcnv1rx8RiJR0R10lEhurqSSRndsk1deKRbSG4TmN16+hrKlXNdL4eQXmlNbnqCQM9vSuFLn1Z6dFxTMtbhulHmMf4z+FX7jTXSQoVwwNV/skidVqNE7Hc0raFcYHerEZLcCkFq7NitG2siFFV7pnYfbRjuOa1oiFXpVWK2K1ZKlVqHY1joPeRnYRp1biuot4hY6OIUGMjJrM8PaU9zcfaJF+UHjNb2pxlYJCBwo4q6cUOc1ax4lrsxfWbk/7VVI5Kk1FS+o3B9XNRIhFE7HFUcS9E9X4b66hb5JnH/AqzYuKnU1jeS2OGfKbcGvzIP3qBx6jg1cXXLR/vlkPuK5kmoXau7DYirFnDVsdaL20l+5Oh+pxSNtbkEH6GuKd6j+2SRfckZfoa+jw2LdtUcMzsmWoHWubj167ixlww9GFW4/EUTYE8ZX3U5FenDExkONzSYVC1Mjvre4/wBXKp9s8041tzJnTEaaaadSUjQgBoxQKM1mQAopKKBhmlpKKAA0tITQK1gIeDRmm4orrgJonjarkTVQQ02TVLe34B3t6Csq3KlqZS0N+J6jvdR+zLsRgZCPyrn/AO2Lh2+TCDtgVGJWdixOSepNfP4upGzUTndRosPK0khJOSepNMIzTAfmqWvAqU9bm1OsyBo81t+F5PJvzETxIOPqKy6ntJRb3cUo/gYHiuRvlZ3U6zPUZdDtdQshP5qxy44ZjgE+lZjeGLnbkxcDqVINaBlDW9mP4TlvxrYhmKr5eT0yD6Vy1Ze9oejRru2pxcmjeVyBn8KiW2KNt212l1bi4j+0R7c5w6D19azjYhuqYrB1WjujLmVzFSH2q5Z6abqQkqfKQZb39qvJp77vkUk+gFdDaWy29goK4Y8sPenGbbFOdkczOLiKQPgps4VV6KK24pl1HRpJMDzFGHX3ps1jNcSHKFVzx71Lb6fJZMzhSdwwy+orX2jRySqM8Q1C3239wMf8tD/OqojxW3rsQi1q8T0lbGayyBVxk2ziqVWMAxS7sUtMrqhC5wzrMGaoXepHNVZDXoUaSMPaNkUj1UkkqWU1TkPNerSgkNK4PLiozJUbmo91dDRpGJL5jDkMQfUGrtvrN1b8b949H5rOzTTU88o7GqR1dlrEVywjcbJD+RrTrg1fawI4IPUV2VhO11ZRSnqRzXXh6znoxi0UUVuIKKKKACiiikAgoooraAhxooorrjsJmTqV1KJBEGwp6471TioorzMZuzKpsXIu1W0oorxKxxSHp96pqKK86oXTCniiivOqnfTPV9JUSWGm7+cwA1q+WsciKucHiiiuKe5309h1wgjTCcZPNVSx3AUUVjPc9Kj8JuW1pGsKMC2WGTzV9beNUXC9aKK0jsZVNyeGGPPTpUF7xGaKKDnZ4T4o/wCRkv8A/rp/SsQ0UVvTOKqMNNoor0KZwVCN6qyUUV6VExRUk71Ukoor0qZ0RK7/AHajFFFbM2QpptFFYSLQldvYIqWUKqMDaDRRXRhPiA//2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "CATEGORIES = ['real', 'fake']\n",
    "\n",
    "model1 = keras.models.load_model('double_trained_model.h5')\n",
    "model2 = keras.models.load_model('model_00_20.h5')\n",
    "model3 = keras.models.load_model('model_20_40.h5')\n",
    "model4 = keras.models.load_model('model_40_60.h5')\n",
    "model5 = keras.models.load_model('model_q2_q4.h5')\n",
    "\n",
    "MODELS = [model1, model2, model3, model4, model5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function ingests a Lists, returns the most frequent value in list\n",
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    " \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_array(img):\n",
    "    pred = []\n",
    "\n",
    "    for mod in MODELS:\n",
    "        predictions = mod.predict(img)\n",
    "        pred.append(int(predictions[0][0]))\n",
    "    #append the most frequent result on total_pred list so that we return 1 list\n",
    "    pred.append(most_frequent(pred))\n",
    "    #print(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, classIdx, layerName=None):\n",
    "        self.model = model\n",
    "        self.classIdx = classIdx\n",
    "        self.layerName = layerName\n",
    "        if self.layerName is None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "\n",
    "    #setter has list in parameters\n",
    "    def set_model(self, mod):\n",
    "        self.model = mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_layer(model):\n",
    "\t# attempt to find the final convolutional layer in the network\n",
    "\t# by looping over the layers of the network in reverse order\n",
    "\tfor layer in reversed(model.layers):\n",
    "\t\t# check to see if the layer has a 4D output\n",
    "\t\tif len(layer.output_shape) == 4:\n",
    "\t\t\treturn layer.name\n",
    "\t# otherwise, we could not find a 4D layer so the GradCAM\n",
    "\t# algorithm cannot be applied\n",
    "\traise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heatmap(self, image, eps=1e-8):\n",
    "    # construct our gradient model by supplying (1) the inputs\n",
    "    # to our pre-trained model, (2) the output of the (presumably)\n",
    "    # final 4D layer in the network, and (3) the output of the\n",
    "    # softmax activations from the model\n",
    "    gradModel = Model(\n",
    "        inputs=[self.model.inputs],\n",
    "        outputs=[self.model.get_layer(self.layerName).output,\n",
    "            self.model.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_predictions(img_path):\n",
    "    #parameter is path to input file on local machine \n",
    "    #convert image to grayscale \n",
    "    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #plt.imshow(img_array, cmap=\"gray\")\n",
    "    #plt.show()\n",
    "\n",
    "    #resize image to fit model input layer\n",
    "    img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    img_array = img_array.reshape(-1, 128, 128, 1)\n",
    "    #compute_heatmap(img_array)\n",
    "\n",
    "    #i = 0\n",
    "    temp_list = []\n",
    "    #make a prediction with each model\n",
    "    for mod in MODELS:\n",
    "        target_layer_name = find_target_layer(mod)\n",
    "        #print(target_layer_name)\n",
    "        predictions = mod.predict(img_array)\n",
    "        temp_list.append(int(predictions[0][0]))\n",
    "\n",
    "        #heatmap\n",
    "        # Remove last layer's softmax\n",
    "        mod.layers[-1].activation = None\n",
    "\n",
    "        \n",
    "        # Print what the top predicted class is\n",
    "        preds = mod.predict(img_array)\n",
    "        #print(\"Predicted Class Model \" + str(i) + \": \" + CATEGORIES[int(predictions[0][0])])\n",
    "        #i = i + 1\n",
    "    pred = prediction_array(img_array)\n",
    "    print(\"hey\")\n",
    "    print(len(pred))\n",
    "    print(\"Predicted:\", decode_predictions(pred, top=1)[0])\n",
    "    #print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_array, mod, last_conv_layer_name)\n",
    "\n",
    "    # Display heatmap\n",
    "    plt.matshow(heatmap)\n",
    "    plt.show()\n",
    "    #print(\"here\")\n",
    "    #print(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hey\n",
      "6\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\624411\\Desktop\\gui\\test_hm.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=0'>1</a>\u001b[0m get_list_of_predictions(img_path)\n",
      "\u001b[1;32mc:\\Users\\624411\\Desktop\\gui\\test_hm.ipynb Cell 12\u001b[0m in \u001b[0;36mget_list_of_predictions\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhey\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(pred))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPredicted:\u001b[39m\u001b[39m\"\u001b[39m, decode_predictions(pred, top\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=34'>35</a>\u001b[0m \u001b[39m#print(\"Predicted:\", decode_predictions(preds, top=1)[0])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=35'>36</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=36'>37</a>\u001b[0m \u001b[39m# Generate class activation heatmap\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/624411/Desktop/gui/test_hm.ipynb#ch0000007?line=37'>38</a>\u001b[0m heatmap \u001b[39m=\u001b[39m make_gradcam_heatmap(img_array, mod, last_conv_layer_name)\n",
      "File \u001b[1;32mc:\\Users\\624411\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\applications\\xception.py:324\u001b[0m, in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.applications.xception.decode_predictions\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_predictions\u001b[39m(preds, top\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n\u001b[1;32m--> 324\u001b[0m   \u001b[39mreturn\u001b[39;00m imagenet_utils\u001b[39m.\u001b[39;49mdecode_predictions(preds, top\u001b[39m=\u001b[39;49mtop)\n",
      "File \u001b[1;32mc:\\Users\\624411\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:146\u001b[0m, in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m\"\"\"Decodes the prediction of an ImageNet model.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m    (must be 2D).\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39mglobal\u001b[39;00m CLASS_INDEX\n\u001b[1;32m--> 146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(preds\u001b[39m.\u001b[39;49mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m preds\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m    147\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`decode_predictions` expects \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    148\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39ma batch of predictions \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    149\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m(i.e. a 2D array of shape (samples, 1000)). \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    150\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mFound array with shape: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(preds\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m CLASS_INDEX \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "get_list_of_predictions(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c466081faad3890721e1057afad1ed119f8f73d11717f0d7d135755f98d78ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
